{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ABuDhptqkTF"
      },
      "source": [
        "# Notebook\n",
        "version 15h55 Tu Jan 21, sent by Raphael Zaghroun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LP9eKvz0FxN"
      },
      "source": [
        "## Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/trenaudie/Documents/cours/mines_3a/aneurysms/ButterflyAnevrisme/venv/bin/python\n"
          ]
        }
      ],
      "source": [
        "import sys \n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "print(CUDA_version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu 2.5.1\n"
          ]
        }
      ],
      "source": [
        "if CUDA_version is not None:\n",
        "    CUDA = format_cuda_version(CUDA_version)\n",
        "    print(CUDA, TORCH)\n",
        "else:\n",
        "    CUDA = 'cpu'\n",
        "    print(CUDA, TORCH)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.17.1'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensorboard.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "peTxoYYkFNSQ",
        "outputId": "ecb53edb-bc1c-4ab7-f55d-06dc55dc2194"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import enum\n",
        "import gc\n",
        "import os\n",
        "import os.path as osp\n",
        "import shutil\n",
        "import sys\n",
        "from itertools import product\n",
        "from typing import List\n",
        "# Third-party library imports\n",
        "import meshio\n",
        "import numpy as np\n",
        "import torch\n",
        "from loguru import logger\n",
        "from torch.nn.modules.loss import _Loss\n",
        "from torch.utils.data import DataLoader, Dataset as BaseDataset\n",
        "from torch_scatter import scatter_add\n",
        "import torch.nn as nn\n",
        "from torch_geometric.data import Data\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M4qvmnU0JXJ"
      },
      "source": [
        "## Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "G5Gwdb5VC_0v",
        "outputId": "f42b0b48-f578-4db9-d059-cf66f735ed05"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Dataset(BaseDataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        folder_path: str,\n",
        "    ):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.folder_path = folder_path\n",
        "        self.files = os.listdir(folder_path)\n",
        "        self.files = [file for file in self.files if file.endswith(\".xdmf\")]\n",
        "        self.files.sort()\n",
        "        self.len_time = 79\n",
        "        self.number_files = len(self.files) * self.len_time\n",
        "        self.encode_id = {i*self.len_time+t:(i,t) for t,i in product(range(self.len_time),range(len(self.files)))}\n",
        "\n",
        "    def __len__(self):\n",
        "      return self.number_files\n",
        "\n",
        "    def __getitem__(self,id):\n",
        "        i,t = self.encode_id[id]\n",
        "        meshes = self.xdmf_to_meshes(self.folder_path+self.files[i],t)\n",
        "        mesh = meshes[0]\n",
        "\n",
        "        #Get data from mesh\n",
        "        data, pos, edges, edges_attr = self.mesh_to_graph_data(mesh,t)\n",
        "\n",
        "        #Get speed for t+1 mesh\n",
        "        next_t_mesh = meshes[1]\n",
        "        next_data = self.get_speed_data(next_t_mesh,t+1)\n",
        "        del meshes\n",
        "\n",
        "        #Structure the information\n",
        "        current_graph_data = {\n",
        "                              \"x\":data,\n",
        "                              \"pos\":pos,\n",
        "                              \"edge_index\":edges,\n",
        "                              \"edge_attr\":edges_attr,\n",
        "                              \"y\":next_data[:,:-2],\n",
        "                              }\n",
        "\n",
        "        # graph_data = Data(x=current_graph_data['x'],\n",
        "        #pos=current_graph_data['pos'],\n",
        "        #                         edge_index=current_graph_data['edge_index'],\n",
        "        #                         edge_attr=current_graph_data['edge_attr'],\n",
        "        #                         y=current_graph_data['y'])\n",
        "\n",
        "        return current_graph_data\n",
        "\n",
        "    def get_speed_data(self,mesh,t):\n",
        "        time_array = np.full(mesh.point_data['Pression'][:,None].shape, fill_value=t*1e-2)\n",
        "        data = torch.from_numpy(np.concatenate([mesh.point_data['Vitesse'],\n",
        "                                                  mesh.point_data['Pression'][:,None],\n",
        "                                                  time_array],axis=1))\n",
        "        return data\n",
        "\n",
        "    def mesh_to_graph_data(self,mesh,t):\n",
        "        node_edges = []\n",
        "        edges_attr_ = []\n",
        "        for tetra in mesh.cells_dict['tetra']:\n",
        "            for node,neighbor in product(tetra,tetra):\n",
        "                if node != neighbor:\n",
        "                    node_edges.append([node,neighbor])\n",
        "                    edges_attr_.append(mesh.points[neighbor]-mesh.points[node])\n",
        "        edges = torch.from_numpy(np.array(node_edges).T)\n",
        "        edges_attr = torch.from_numpy(np.array(edges_attr_))\n",
        "        pos = torch.from_numpy(mesh.points)\n",
        "        wall_labels = self.classify_vertices(mesh, \"Vitesse\")  # Assuming classify_vertices returns 0 for wall, 1 for others\n",
        "        wall_labels_tensor = torch.tensor(wall_labels).unsqueeze(1)  # Convert to tensor and add dimension\n",
        "        data = self.get_speed_data(mesh,t)\n",
        "        data = torch.cat([data, wall_labels_tensor], dim=1)  # Concatenate with data\n",
        "        return data, pos, edges, edges_attr\n",
        "\n",
        "    @staticmethod\n",
        "    def classify_vertices(mesh: meshio.Mesh, velocity_key: str = \"Vitesse\") -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Classify each vertex of the mesh as being on the wall or in the flow.\n",
        "\n",
        "        Parameters:\n",
        "            mesh: The mesh object containing point data.\n",
        "            velocity_key: The key for the velocity data in the mesh point_data.\n",
        "\n",
        "        Returns:\n",
        "            A numpy array of labels (0 for wall, 1 for flow).\n",
        "        \"\"\"\n",
        "        if velocity_key not in mesh.point_data:\n",
        "            raise ValueError(f\"Velocity data key '{velocity_key}' not found in mesh point_data.\")\n",
        "\n",
        "        velocities = np.array(mesh.point_data[velocity_key])  # Shape: (num_points, 3)\n",
        "        speed_norm = np.linalg.norm(velocities, axis=1)  # Compute the norm of velocity for each vertex\n",
        "        labels = np.where(speed_norm <= 1e-8, 0, 1)  # 0 for wall, 1 for flow\n",
        "        return labels\n",
        "\n",
        "    @staticmethod\n",
        "    def xdmf_to_meshes(xdmf_file_path: str, t) -> List[meshio.Mesh]:\n",
        "        \"\"\"\n",
        "        Opens an XDMF archive file, and extract a data mesh object for every timestep.\n",
        "\n",
        "        xdmf_file_path: path to the .xdmf file.\n",
        "        Returns: list of data mesh objects.\n",
        "        \"\"\"\n",
        "\n",
        "        reader = meshio.xdmf.TimeSeriesReader(xdmf_file_path)\n",
        "        points, cells = reader.read_points_cells()\n",
        "        meshes = []\n",
        "\n",
        "        # Extracting the meshes from the archive\n",
        "        for i in [t,t+1]:\n",
        "            # Depending on meshio version, the function read_data may return 3 or 4 values.\n",
        "            try:\n",
        "                time, point_data, cell_data, _ = reader.read_data(i)\n",
        "            except ValueError:\n",
        "                time, point_data, cell_data = reader.read_data(i)\n",
        "            mesh = meshio.Mesh(points, cells, point_data=point_data, cell_data=cell_data)\n",
        "            meshes.append(mesh)\n",
        "        print(f\"Loaded {len(meshes)} timesteps from {xdmf_file_path.split('/')[-1]}\\n\")\n",
        "        return meshes\n",
        "\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/IDSC/4Students_AnXplore03/'\n",
        "\n",
        "# dataset = Dataset(folder_path)\n",
        "# train_loader = DataLoader(\n",
        "#     dataset=dataset,\n",
        "#     batch_size=1,\n",
        "#     shuffle=True,\n",
        "#     num_workers=2,\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjEAxUm20OOI"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xCOa7sgUDMEs"
      },
      "outputs": [],
      "source": [
        "def build_mlp(\n",
        "    in_size: int,\n",
        "    hidden_size: int,\n",
        "    out_size: int,\n",
        "    nb_of_layers: int = 4,\n",
        "    lay_norm: bool = True,\n",
        ") -> nn.Module:\n",
        "    \"\"\"\n",
        "    Builds a Multilayer Perceptron (MLP) using PyTorch.\n",
        "\n",
        "    Parameters:\n",
        "        - in_size (int): The size of the input layer.\n",
        "        - hidden_size (int): The size of the hidden layers.\n",
        "        - out_size (int): The size of the output layer.\n",
        "        - nb_of_layers (int, optional): The number of layers in the MLP, including the input and output layers. Defaults to 4.\n",
        "\n",
        "    Returns:\n",
        "        - nn.Module: The constructed MLP model.\n",
        "    \"\"\"\n",
        "    # Initialize the model with the first layer.\n",
        "    layers = []\n",
        "    layers.append(nn.Linear(in_size,hidden_size))\n",
        "    layers.append(nn.ReLU())\n",
        "\n",
        "    if lay_norm:\n",
        "      layers.append(nn.LayerNorm(hidden_size))\n",
        "\n",
        "    for _ in range(nb_of_layers - 2):\n",
        "      layers.append(nn.Linear(hidden_size,hidden_size))\n",
        "      layers.append(nn.ReLU())\n",
        "\n",
        "      if lay_norm:\n",
        "        layers.append(nn.LayerNorm(hidden_size))\n",
        "\n",
        "    # Add the output layer\n",
        "      layers.append(nn.Linear(hidden_size,out_size))\n",
        "\n",
        "    # Construct the model using the specified layers.\n",
        "    module = nn.Sequential(*layers)\n",
        "\n",
        "    return module\n",
        "\n",
        "class EdgeBlock(nn.Module):\n",
        "    \"\"\"A block that updates the attributes of the edges in a graph based on the features of the\n",
        "    sending and receiving nodes, as well as the original edge attributes.\n",
        "\n",
        "    Attributes:\n",
        "        model_fn (callable): A function to update edge attributes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_fn=None):\n",
        "\n",
        "        super(EdgeBlock, self).__init__()\n",
        "        self._model_fn = model_fn\n",
        "\n",
        "    def forward(self, graph):\n",
        "        \"\"\"Forward pass of the EdgeBlock.\n",
        "\n",
        "        Args:\n",
        "            graph (Data): A graph containing node attributes, edge indices, and edge attributes.\n",
        "\n",
        "        Returns:\n",
        "            Data: An updated graph with new edge attributes.\n",
        "        \"\"\"\n",
        "        edge_inputs = torch.concat(\n",
        "            [\n",
        "                graph.edge_attr,\n",
        "                graph.x[graph.edge_index[0]],\n",
        "                graph.x[graph.edge_index[1]]\n",
        "            ], dim=1\n",
        "        )\n",
        "        # print(f'edge_inputs {edge_inputs.shape}')\n",
        "\n",
        "        edge_attr_ = self._model_fn(edge_inputs)\n",
        "\n",
        "        return Data(\n",
        "                x=graph.x, edge_attr=edge_attr_, edge_index=graph.edge_index, pos=graph.pos\n",
        "            )\n",
        "\n",
        "\n",
        "class NodeBlock(nn.Module):\n",
        "    \"\"\"A block that updates the attributes of the nodes in a graph based on the aggregated features\n",
        "    of the incoming edges and the original node attributes.\n",
        "\n",
        "    Attributes:\n",
        "        model_fn (callable): A function to update node attributes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_fn=None):\n",
        "\n",
        "        super(NodeBlock, self).__init__()\n",
        "\n",
        "        self._model_fn = model_fn\n",
        "\n",
        "    def forward(self, graph):\n",
        "        \"\"\"Forward pass of the NodeBlock.\n",
        "\n",
        "        Args:\n",
        "            graph (Data): A graph containing node attributes, edge indices, and edge attributes.\n",
        "\n",
        "        Returns:\n",
        "            Data: An updated graph with new node attributes.\n",
        "        \"\"\"\n",
        "        edge_attr = graph.edge_attr\n",
        "        receivers_indx = graph.edge_index[1]\n",
        "        agrr_edge_features = scatter_add(\n",
        "            edge_attr, receivers_indx, dim=0, dim_size=graph.num_nodes\n",
        "        )\n",
        "        node_inputs = torch.cat(\n",
        "            [graph.x, agrr_edge_features], dim=-1\n",
        "        )\n",
        "\n",
        "        x_ = self._model_fn(node_inputs)\n",
        "\n",
        "        return Data(\n",
        "                x=x_, edge_attr=graph.edge_attr, edge_index=graph.edge_index, pos=graph.pos\n",
        "            )\n",
        "\n",
        "class GraphNetBlock(nn.Module):\n",
        "    \"\"\"A block that sequentially applies an EdgeBlock and a NodeBlock to update the attributes of\n",
        "    both edges and nodes in a graph.\n",
        "\n",
        "    Attributes:\n",
        "        edge_block (EdgeBlock): The block to update edge attributes.\n",
        "        node_block (NodeBlock): The block to update node attributes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size=128,\n",
        "        use_batch=False,\n",
        "        use_gated_mlp=False,\n",
        "        use_gated_lstm=False,\n",
        "        use_gated_mha=False,\n",
        "    ):\n",
        "\n",
        "        super(GraphNetBlock, self).__init__()\n",
        "\n",
        "        edge_input_dim = 3*hidden_size #3*128=384\n",
        "        node_input_dim = 2*hidden_size #2*128=256\n",
        "\n",
        "        self.edge_block = EdgeBlock(model_fn=build_mlp(\n",
        "            in_size=edge_input_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            out_size=hidden_size,\n",
        "        )) #\n",
        "        self.node_block = NodeBlock(\n",
        "            model_fn=build_mlp(\n",
        "                in_size=node_input_dim,\n",
        "                hidden_size=hidden_size,\n",
        "                out_size=hidden_size,\n",
        "            )\n",
        "        ) #\n",
        "\n",
        "    def _apply_sub_block(self, graph):\n",
        "        graph = self.edge_block(graph)\n",
        "        return self.node_block(graph)\n",
        "\n",
        "    def forward(self, graph):\n",
        "\n",
        "        graph_last = graph.clone()\n",
        "        graph = self._apply_sub_block(graph)\n",
        "\n",
        "        edge_attr = graph_last.edge_attr + graph.edge_attr\n",
        "        x = graph_last.x + graph.x\n",
        "\n",
        "        return Data(\n",
        "                x=x, edge_attr=edge_attr, edge_index=graph.edge_index, pos=graph.pos\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lyhBNYfoDGHb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6zblL8b31Ng-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM410W6b0Sh3"
      },
      "source": [
        "## Training Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Wn92lE9MDITu"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class Epoch:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        loss,\n",
        "        stage_name,\n",
        "        parameters,\n",
        "        device=\"cpu\",\n",
        "        verbose=True,\n",
        "        starting_step=0,\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.loss = loss\n",
        "        self.verbose = verbose\n",
        "        self.device = device\n",
        "        self.parameters = parameters\n",
        "        self.step = 0\n",
        "        self._to_device()\n",
        "        self.stage_name = stage_name\n",
        "        self.full_batch_graph = []\n",
        "        self.starting_step = starting_step\n",
        "\n",
        "    def _to_device(self):\n",
        "        self.model.to(self.device)\n",
        "        self.loss.to(self.device)\n",
        "\n",
        "    def _format_logs(self, logs):\n",
        "        str_logs = [\"{} - {:.4}\".format(k, v) for k, v in logs.items()]\n",
        "        s = \", \".join(str_logs)\n",
        "        return s\n",
        "\n",
        "    def batch_update(self, x, y):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def on_epoch_start(self):\n",
        "        pass\n",
        "\n",
        "    def run(self, dataloader, writer=None, model_save_dir=\"checkpoint/simulator.pth\"):\n",
        "\n",
        "        self.on_epoch_start()\n",
        "\n",
        "        logs = {}\n",
        "        loss_meter = AverageValueMeter()\n",
        "\n",
        "        with tqdm(\n",
        "            dataloader,\n",
        "            desc=self.stage_name,\n",
        "            file=sys.stdout,\n",
        "            disable=not (self.verbose),\n",
        "        ) as iterator:\n",
        "            for graph_data in iterator:\n",
        "                for indx in range(1):\n",
        "                    #TODO: check if we need this processing or not because it may already be the case\n",
        "                    input_graph = Data(\n",
        "                        x=graph_data[\"x\"][indx],\n",
        "                        pos=graph_data[\"pos\"][indx],\n",
        "                        edge_index=graph_data[\"edge_index\"][indx],\n",
        "                        edge_attr=graph_data.get(\"edge_attr\", [None])[indx],\n",
        "                        y=graph_data[\"y\"][indx],\n",
        "                    ).to(self.device)\n",
        "                    # input_graph = graph_data.to(self.device)\n",
        "\n",
        "                    self.full_batch_graph.append(input_graph)\n",
        "\n",
        "                if len(self.full_batch_graph) % self.model.batch_size == 0:\n",
        "\n",
        "                    loss = self.batch_update(self.full_batch_graph, writer)\n",
        "\n",
        "                    # update loss logs\n",
        "                    loss_value = loss.cpu().detach().numpy()\n",
        "                    loss_meter.add(loss_value)\n",
        "                    loss_logs = {self.loss.__name__: loss_meter.mean}\n",
        "                    logs.update(loss_logs)\n",
        "\n",
        "                    if self.model.training:\n",
        "                        writer.add_scalar(\n",
        "                            \"Loss/train/value_per_step\",\n",
        "                            loss_value,\n",
        "                            self.step + self.starting_step,\n",
        "                        )\n",
        "\n",
        "                    else:\n",
        "                        writer.add_scalar(\n",
        "                            \"Loss/test/value_per_step\",\n",
        "                            loss_value,\n",
        "                            self.step + self.starting_step,\n",
        "                        )\n",
        "\n",
        "                    if self.step % 200 == 0:\n",
        "                        self.model.save_checkpoint(model_save_dir)\n",
        "                        writer.flush()\n",
        "\n",
        "                    self.step += 1\n",
        "                    self.full_batch_graph = []\n",
        "\n",
        "                    if self.verbose:\n",
        "                        s = self._format_logs(logs)\n",
        "                        iterator.set_postfix_str(s)\n",
        "\n",
        "        return loss_meter.mean\n",
        "\n",
        "\n",
        "class TrainEpoch(Epoch):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        loss,\n",
        "        parameters,\n",
        "        optimizer,\n",
        "        device=\"cpu\",\n",
        "        verbose=True,\n",
        "        starting_step=0,\n",
        "        use_sub_graph=False,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            model=model,\n",
        "            loss=loss,\n",
        "            stage_name=\"train\",\n",
        "            parameters=parameters,\n",
        "            device=device,\n",
        "            verbose=verbose,\n",
        "            starting_step=starting_step,\n",
        "        )\n",
        "        self.optimizer = optimizer\n",
        "        self.use_sub_graph = use_sub_graph\n",
        "\n",
        "    def on_epoch_start(self):\n",
        "        self.model.train()\n",
        "\n",
        "    def batch_update(self, batch_graph, writer):\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = 0\n",
        "        #TODO: check that batch_graph is either a list of graphs of a list of one list of graphs\n",
        "        for graph in batch_graph:\n",
        "            node_type = graph['x'][:, self.model.node_type_index]\n",
        "            network_output, target_delta_normalized = self.model(graph)\n",
        "            loss += self.loss(\n",
        "                target_delta_normalized,\n",
        "                network_output,\n",
        "                node_type,\n",
        "            )\n",
        "\n",
        "        loss /= len(batch_graph)\n",
        "        loss.backward()\n",
        "        max_norm = 10.0\n",
        "        nn.utils.clip_grad_norm_(self.model.parameters(), max_norm)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pQpAlzSiKwOZ"
      },
      "outputs": [],
      "source": [
        "class Meter(object):\n",
        "    \"\"\"Meters provide a way to keep track of important statistics in an online manner.\n",
        "    This class is abstract, but provides a standard interface for all meters to follow.\n",
        "    \"\"\"\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the meter to default settings.\"\"\"\n",
        "\n",
        "    def add(self, value):\n",
        "        \"\"\"Log a new value to the meter\n",
        "        Args:\n",
        "            value: Next result to include.\n",
        "        \"\"\"\n",
        "\n",
        "    def value(self):\n",
        "        \"\"\"Get the value of the meter in the current state.\"\"\"\n",
        "\n",
        "class AverageValueMeter(Meter):\n",
        "    def __init__(self):\n",
        "        super(AverageValueMeter, self).__init__()\n",
        "        self.reset()\n",
        "        self.val = 0\n",
        "\n",
        "    def add(self, value, n=1):\n",
        "        self.val = value\n",
        "        self.sum += value\n",
        "        self.var += value * value\n",
        "        self.n += n\n",
        "\n",
        "        if self.n == 0:\n",
        "            self.mean, self.std = np.nan, np.nan\n",
        "        elif self.n == 1:\n",
        "            self.mean = 0.0 + self.sum  # This is to force a copy in torch/numpy\n",
        "            self.std = np.inf\n",
        "            self.mean_old = self.mean\n",
        "            self.m_s = 0.0\n",
        "        else:\n",
        "            self.mean = self.mean_old + (value - n * self.mean_old) / float(self.n)\n",
        "            self.m_s += (value - self.mean_old) * (value - self.mean)\n",
        "            self.mean_old = self.mean\n",
        "            self.std = np.sqrt(self.m_s / (self.n - 1.0))\n",
        "\n",
        "    def value(self):\n",
        "        return self.mean, self.std\n",
        "\n",
        "    def reset(self):\n",
        "        self.n = 0\n",
        "        self.sum = 0.0\n",
        "        self.var = 0.0\n",
        "        self.val = 0.0\n",
        "        self.mean = np.nan\n",
        "        self.mean_old = 0.0\n",
        "        self.m_s = 0.0\n",
        "        self.std = np.nan\n",
        "\n",
        "class L2Loss(_Loss):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    @property\n",
        "    def __name__(self):\n",
        "        return \"MSE\"\n",
        "\n",
        "    def forward(\n",
        "        self, target_speed, network_output, node_type\n",
        "    ):\n",
        "        \"Computes L2 loss on velocity, with respect to the noise\"\n",
        "        mask = (node_type == 1)\n",
        "        errors = (target_speed[mask] - network_output[mask]) ** 2\n",
        "        return torch.mean(errors)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxPHDQaz0XjQ"
      },
      "source": [
        "## Objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "qAfKKq0CDdsy"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#from DataLoader import Dataset\n",
        "#from EncoderDecoder import EncodeProcessDecode\n",
        "#from Utils import L2Loss, Simulator\n",
        "#from Epoch import TrainEpoch\n",
        "\n",
        "writer = SummaryWriter(\"tensorboard\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "folder_path = 'data/'\n",
        "dataset = Dataset(folder_path)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    #multiprocessing_context='spawn'\n",
        ")\n",
        "\n",
        "model = EncodeProcessDecode(\n",
        "    node_input_size=6,\n",
        "    edge_input_size=3,\n",
        "    message_passing_num=15,\n",
        "    hidden_size=128,\n",
        "    output_size=3,\n",
        ") #\n",
        "loss = L2Loss() #\n",
        "simulator = Simulator(\n",
        "    node_input_size=6,\n",
        "    edge_input_size=3,\n",
        "    output_size=3,\n",
        "    feature_index_start=0,\n",
        "    feature_index_end=4,\n",
        "    output_index_start=0,\n",
        "    output_index_end=3,\n",
        "    node_type_index=5,\n",
        "    batch_size=1,\n",
        "    model=model,\n",
        "    device=device,\n",
        "    model_dir=\"checkpoint/simulator.pth\",\n",
        "    time_index=4\n",
        ") #\n",
        "optimizer = torch.optim.Adam(simulator.parameters(), lr=0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPZnUvIhs64E",
        "outputId": "b7022953-2a64-4980-a335-8c9569f109ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 2 timesteps from AllFields_Resultats_MESH_194.xdmf\n",
            "\n",
            "{'x': tensor([[[-3.2071e-14,  1.0350e-14,  3.1645e-15,  5.3006e+02,  1.0000e-02,\n",
            "           0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.2887e+02,  1.0000e-02,\n",
            "           0.0000e+00],\n",
            "         [ 3.8355e-13, -1.3933e-13,  1.0816e-14,  5.2624e+02,  1.0000e-02,\n",
            "           0.0000e+00],\n",
            "         ...,\n",
            "         [ 2.4687e+02,  1.4630e+01,  4.1076e+01,  5.9381e+02,  1.0000e-02,\n",
            "           1.0000e+00],\n",
            "         [-3.0978e+01, -3.2599e+01,  4.9582e+00,  6.0487e+02,  1.0000e-02,\n",
            "           1.0000e+00],\n",
            "         [ 2.8117e+02, -1.9362e+02,  9.7901e+00,  5.1412e+02,  1.0000e-02,\n",
            "           1.0000e+00]]], dtype=torch.float64), 'pos': tensor([[[ 1.0591e+00,  4.0783e+00,  4.9301e-01],\n",
            "         [ 1.1285e+00,  4.0054e+00,  2.1423e-01],\n",
            "         [ 1.2922e+00,  3.9372e+00, -2.3159e-02],\n",
            "         ...,\n",
            "         [-3.3884e+00,  5.8008e+00,  1.6536e+00],\n",
            "         [ 3.8517e-02,  1.1090e+01,  9.3458e-04],\n",
            "         [ 3.5942e+00,  4.3794e+00, -8.8414e-01]]]), 'edge_index': tensor([[[4855, 4855, 4855,  ..., 6175, 6175, 6175],\n",
            "         [4856, 4857, 4858,  ..., 8915, 4475, 8060]]]), 'edge_attr': tensor([[[-0.1006,  0.2523, -0.0014],\n",
            "         [-0.1474,  0.0842, -0.4456],\n",
            "         [-0.3008, -0.0352, -0.1324],\n",
            "         ...,\n",
            "         [-0.1493,  0.2672,  0.1717],\n",
            "         [-0.1597, -0.3018,  0.2851],\n",
            "         [-0.3317,  0.0099,  0.1005]]]), 'y': tensor([[[-3.9138e-14,  1.2723e-14,  4.4839e-15],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "         [ 4.6888e-13, -1.6954e-13,  1.5472e-14],\n",
            "         ...,\n",
            "         [ 2.7885e+02,  1.6839e+01,  4.6239e+01],\n",
            "         [-3.1679e+01, -3.2727e+01,  4.9528e+00],\n",
            "         [ 3.1689e+02, -2.1750e+02,  8.5876e+00]]], dtype=torch.float64)}\n"
          ]
        }
      ],
      "source": [
        "for batch in train_loader:\n",
        "    print(batch)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_5NLhuAZeqF",
        "outputId": "e45d85e3-0e66-4339-d173-06c52a72e53d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([11704, 6])\n",
            "torch.Size([11704, 3])\n",
            "torch.Size([2, 682788])\n",
            "torch.Size([682788, 3])\n",
            "torch.Size([11704, 3])\n"
          ]
        }
      ],
      "source": [
        "batch.keys()\n",
        "# def build_graph_from_batch\n",
        "simulator.batch_size\n",
        "graph_data = batch\n",
        "indx = 0\n",
        "input_graph = Data(\n",
        "            x=graph_data[\"x\"][indx],\n",
        "            pos=graph_data[\"pos\"][indx],\n",
        "            edge_index=graph_data[\"edge_index\"][indx],\n",
        "            edge_attr=graph_data.get(\"edge_attr\", [None])[indx],\n",
        "            y=graph_data[\"y\"][indx],\n",
        "    ).to(simulator.device)\n",
        "graph = input_graph\n",
        "x = graph.x\n",
        "pos = graph.pos\n",
        "edge_index = graph.edge_index\n",
        "edge_attr = graph.edge_attr\n",
        "y = graph.y\n",
        "print(x.shape)\n",
        "print(pos.shape)\n",
        "print(edge_index.shape)\n",
        "print(edge_attr.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RBQW8iljt8x",
        "outputId": "b0fa45b3-88d2-4687-ee80-380d442fc374"
      },
      "outputs": [],
      "source": [
        "encoder = model.encoder\n",
        "encoder\n",
        "encoded_graph = encoder(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdmB9Vu5kQ6P",
        "outputId": "92b2ba68-2162-40d7-b712-9a9622c9c4ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(x=[11732, 128], edge_index=[2, 684396], edge_attr=[684396, 128], y=[11732, 3], pos=[11732, 3])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "encoded_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K6nXM5DkTqf",
        "outputId": "b1abbb73-05eb-4eca-bb0a-5fc226d0dc28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EdgeBlock(\n",
              "  (_model_fn): Sequential(\n",
              "    (0): Linear(in_features=384, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "edge_block = model.processer_list[0].edge_block\n",
        "edge_block\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bR8k6BWke3s",
        "outputId": "98da5886-4fd3-4268-e918-3c5e79ae4447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "edge_inputs torch.Size([682788, 384])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Data(x=[11704, 128], edge_index=[2, 682788], edge_attr=[682788, 128], pos=[11704, 3])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "after_edge = edge_block(encoded_graph)\n",
        "after_edge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vvs6hASZ6vs",
        "outputId": "9d51a7e2-af4b-4a03-8a9c-87f27f3faa81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph = graph.to(\"cpu\")\n",
        "simulator = simulator.to(\"cpu\")\n",
        "simulator.device = \"cpu\"\n",
        "encoded_graph = simulator.encoder(graph)\n",
        "encoded_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "FzM0J62MZabR",
        "outputId": "663154e4-c0ff-4649-8fcd-764a8b567dba"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'batch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7f9235f51273>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#dict_keys(['x', 'pos', 'edge_index', 'edge_attr', 'y'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_input_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "batch.keys()\n",
        "#dict_keys(['x', 'pos', 'edge_index', 'edge_attr', 'y'])\n",
        "simulator._build_input_graph(batch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNiuT_67wpaw",
        "outputId": "0de813f3-b950-4012-d76c-0070e4a88a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11539, 6])\n",
            "torch.Size([1, 11539, 3])\n",
            "torch.Size([1, 2, 673452])\n",
            "torch.Size([1, 673452, 3])\n",
            "torch.Size([1, 11539, 3])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x, pos, edge_index, edge_attr, y = batch['x'], batch['pos'], batch['edge_index'], batch['edge_attr'], batch['y']\n",
        "x.shape #features\n",
        "print(x.shape)\n",
        "print(pos.shape) #coordinates, should not move\n",
        "print(edge_index.shape) #edges\n",
        "print(edge_attr.shape) #edge features\n",
        "print(y.shape) #target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyDB1AL54yeI"
      },
      "outputs": [],
      "source": [
        "\n",
        "input_graph = Data(\n",
        "        x=graph_data[\"x\"][indx],\n",
        "        pos=graph_data[\"pos\"][indx],\n",
        "        edge_index=graph_data[\"edge_index\"][indx],\n",
        "        edge_attr=graph_data.get(\"edge_attr\", [None])[indx],\n",
        "        y=graph_data[\"y\"][indx],\n",
        "    ).to(self.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISAUyS6BtCSQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"now onto training !\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srnRw0KBs_Ja"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            "=== Training ===\n",
            "train:   0%|          | 0/8137 [00:00<?, ?it/s]Loaded 2 timesteps from AllFields_Resultats_MESH_42-1.xdmf\n",
            "\n",
            "edge_inputs torch.Size([697272, 384])\n",
            "edge_inputs torch.Size([697272, 384])\n",
            "edge_inputs torch.Size([697272, 384])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "train_epoch = TrainEpoch(\n",
        "    model=simulator,\n",
        "    loss=loss,\n",
        "    optimizer=optimizer,\n",
        "    parameters={},\n",
        "    device=device,\n",
        "    verbose=True,\n",
        "    starting_step=0,\n",
        "    use_sub_graph=False,\n",
        ")  #\n",
        "\n",
        "for i in range(0, 10):\n",
        "    print(\"\\nEpoch: {}\".format(i))\n",
        "    print(\"=== Training ===\")\n",
        "    train_loss = train_epoch.run(train_loader, writer, \"model.pth\")\n",
        "\n",
        "    writer.add_scalar(\"Loss/train/mean_value_per_epoch\", train_loss, i)\n",
        "    writer.flush()\n",
        "    writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7RoBZKTK4Ju"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2Ih6VHgWsPS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
