{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AoJ54VSs93R",
        "outputId": "5fd0383e-f5da-4715-fbca-11efab0ec4fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cu121 2.5.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "print(CUDA, TORCH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4IVqMp_Ks_cn"
      },
      "outputs": [],
      "source": [
        "#!gdown 1W90lq3I_5RY-Ff48hjR3QoqBzHFAxOiR\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#!mkdir /content/drive/MyDrive/IDSC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6K5Bvg8tP2i",
        "outputId": "539c4d19-366b-4fa8-d6ad-80bdf74268fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.5.1+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt25cu121)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu121.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt25cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu121.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt25cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (1.26.4)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu121.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt25cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.11)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2024.12.14)\n",
            "Requirement already satisfied: loguru==0.7.2 in /usr/local/lib/python3.11/dist-packages (0.7.2)\n",
            "Requirement already satisfied: autoflake==2.3.0 in /usr/local/lib/python3.11/dist-packages (2.3.0)\n",
            "Requirement already satisfied: pyflakes>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from autoflake==2.3.0) (3.2.0)\n",
            "Requirement already satisfied: pytest==8.0.1 in /usr/local/lib/python3.11/dist-packages (8.0.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest==8.0.1) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest==8.0.1) (24.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from pytest==8.0.1) (1.5.0)\n",
            "Requirement already satisfied: meshio==5.3.5 in /usr/local/lib/python3.11/dist-packages (5.3.5)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from meshio==5.3.5) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from meshio==5.3.5) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->meshio==5.3.5) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->meshio==5.3.5) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->meshio==5.3.5) (0.1.2)\n",
            "Requirement already satisfied: h5py==3.10.0 in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from h5py==3.10.0) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric\n",
        "!pip install loguru==0.7.2\n",
        "!pip install autoflake==2.3.0\n",
        "!pip install pytest==8.0.1\n",
        "!pip install meshio==5.3.5\n",
        "!pip install h5py==3.10.0\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "import shutil\n",
        "from itertools import product\n",
        "import meshio\n",
        "from typing import List\n",
        "from torch_geometric.data import Dataset as BaseDataset\n",
        "from torch_geometric.data import Data\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch_geometric.loader import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "n8QpOGI3tSTX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "import shutil\n",
        "from itertools import product\n",
        "import meshio\n",
        "from typing import List\n",
        "from torch_geometric.data import Dataset as BaseDataset\n",
        "from torch_geometric.data import Data\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch_geometric.loader import DataLoader\n",
        "import gc\n",
        "\n",
        "class Dataset(BaseDataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        folder_path: str,\n",
        "    ):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.folder_path = folder_path\n",
        "        self.files = os.listdir(folder_path)\n",
        "        self.files = [file for file in self.files if file.endswith(\".xdmf\")]\n",
        "        self.files.sort()\n",
        "        self.len_time = 79\n",
        "        self.number_files = len(self.files) * self.len_time\n",
        "        self.encode_id = {i*self.len_time+t:(i,t) for t,i in product(range(self.len_time),range(len(self.files)))}\n",
        "\n",
        "    def __len__(self):\n",
        "      return self.number_files\n",
        "\n",
        "    def __getitem__(self,id):\n",
        "        i,t = self.encode_id[id]\n",
        "        meshes = self.xdmf_to_meshes(self.folder_path+self.files[i],t)\n",
        "        mesh = meshes[0]\n",
        "\n",
        "        #Get data from mesh\n",
        "        data, pos, edges, edges_attr = self.mesh_to_graph_data(mesh,t)\n",
        "\n",
        "        #Get speed for t+1 mesh\n",
        "        next_t_mesh = meshes[1]\n",
        "        next_data = self.get_speed_data(next_t_mesh,t+1)\n",
        "        #next_data = torch.cat([next_data, torch.tensor(data[:,5]).unsqueeze(1)], dim=1)\n",
        "        next_data = torch.cat([next_data, data[:,5].clone().detach().unsqueeze(1)], dim=1)\n",
        "\n",
        "\n",
        "        #Structure the information\n",
        "        current_graph_data = {\n",
        "                              \"x\":data,\n",
        "                              \"pos\":pos,\n",
        "                              \"edge_index\":edges,\n",
        "                              \"edge_attr\":edges_attr,\n",
        "                              \"y\":next_data,\n",
        "                              }\n",
        "\n",
        "        # Free up memory\n",
        "        torch.cuda.empty_cache()\n",
        "        return Data(**current_graph_data)\n",
        "\n",
        "    def get_speed_data(self,mesh,t):\n",
        "        time_array = np.full(mesh.point_data['Pression'][:,None].shape, fill_value=t*1e-2)\n",
        "        data = torch.from_numpy(np.concatenate([mesh.point_data['Vitesse'],\n",
        "                                                  mesh.point_data['Pression'][:,None],\n",
        "                                                  time_array],axis=1)).float()\n",
        "\n",
        "        return data.to(self.device)\n",
        "\n",
        "    # def mesh_to_graph_data(self,mesh,t):\n",
        "    #     node_edges = []\n",
        "    #     edges_attr_ = []\n",
        "    #     for a, tetra in enumerate(mesh.cells_dict['tetra']):\n",
        "    #         #if a == 1000:\n",
        "    #         #    break\n",
        "    #         # Only connect each pair of vertices once\n",
        "    #         for i in range(len(tetra)):\n",
        "    #             for j in range(i + 1, len(tetra)):\n",
        "    #                 node_edges.append([tetra[i], tetra[j]])\n",
        "    #                 edges_attr_.append(mesh.points[tetra[j]] - mesh.points[tetra[i]])\n",
        "    #                 # Reverse direction\n",
        "    #                 node_edges.append([tetra[j], tetra[i]])\n",
        "    #                 edges_attr_.append(mesh.points[tetra[i]] - mesh.points[tetra[j]])\n",
        "    #     edges = torch.from_numpy(np.array(node_edges).T).float()\n",
        "    #     edges_attr = torch.from_numpy(np.array(edges_attr_)).float()\n",
        "    #     pos = torch.from_numpy(mesh.points).float()\n",
        "    #     wall_labels = self.classify_vertices(mesh, \"Vitesse\")  # Assuming classify_vertices returns 0 for wall, 1 for others\n",
        "    #     wall_labels_tensor = torch.tensor(wall_labels).unsqueeze(1).float().to(self.device) # Convert to tensor and add dimension\n",
        "    #     data = self.get_speed_data(mesh,t)\n",
        "    #     data = torch.cat([data, wall_labels_tensor], dim=1)  # Concatenate with data\n",
        "\n",
        "    #     return data.to(self.device), pos.to(self.device), edges.to(self.device), edges_attr.to(self.device)\n",
        "\n",
        "    @staticmethod\n",
        "    def classify_vertices(mesh: meshio.Mesh, velocity_key: str = \"Vitesse\") -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Classify each vertex of the mesh as being on the wall or in the flow.\n",
        "\n",
        "        Parameters:\n",
        "            mesh: The mesh object containing point data.\n",
        "            velocity_key: The key for the velocity data in the mesh point_data.\n",
        "\n",
        "        Returns:\n",
        "            A numpy array of labels (0 for wall, 1 for flow).\n",
        "        \"\"\"\n",
        "        if velocity_key not in mesh.point_data:\n",
        "            raise ValueError(f\"Velocity data key '{velocity_key}' not found in mesh.point_data.\")\n",
        "\n",
        "        velocities = np.array(mesh.point_data[velocity_key])  # Shape: (num_points, 3)\n",
        "        speed_norm = np.linalg.norm(velocities, axis=1)  # Compute the norm of velocity for each vertex\n",
        "        labels = np.where(speed_norm <= 1e-8, 0, 1)  # 0 for wall, 1 for flow\n",
        "        return labels\n",
        "\n",
        "    def mesh_to_graph_data(self, mesh, t):\n",
        "        # Extract tetrahedra and points\n",
        "        tetrahedra = torch.tensor(mesh.cells_dict['tetra'], dtype=torch.long, device=self.device)\n",
        "        points = torch.tensor(mesh.points, dtype=torch.float, device=self.device)\n",
        "\n",
        "        # Create edges and edge attributes using tensor operations\n",
        "        node_edges = torch.cat([\n",
        "            tetrahedra[:, [i, j]].reshape(-1, 2)\n",
        "            for i in range(4) for j in range(i + 1, 4)\n",
        "        ], dim=0)\n",
        "\n",
        "        edges_attr = points[node_edges[:, 1]] - points[node_edges[:, 0]]\n",
        "\n",
        "        # Reverse direction edges\n",
        "        reversed_edges = torch.flip(node_edges, dims=[1])\n",
        "        reversed_edges_attr = -edges_attr\n",
        "\n",
        "        node_edges = torch.cat([node_edges, reversed_edges], dim=0).T\n",
        "        edges_attr = torch.cat([edges_attr, reversed_edges_attr], dim=0)\n",
        "\n",
        "        pos = points\n",
        "\n",
        "        # Classify vertices (wall or flow)\n",
        "        wall_labels = self.classify_vertices(mesh, \"Vitesse\")  # Assuming classify_vertices returns 0 for wall, 1 for others\n",
        "        wall_labels_tensor = torch.tensor(wall_labels, dtype=torch.float, device=self.device).unsqueeze(1).to(self.device)  # Convert to tensor and add dimension\n",
        "\n",
        "        data = self.get_speed_data(mesh, t)\n",
        "        data = torch.cat([data, wall_labels_tensor], dim=1)  # Concatenate with data\n",
        "\n",
        "\n",
        "        return data.to(self.device), pos.to(self.device), node_edges.to(self.device), edges_attr.to(self.device)\n",
        "\n",
        "    @staticmethod\n",
        "    def xdmf_to_meshes(xdmf_file_path: str, t) -> List[meshio.Mesh]:\n",
        "        \"\"\"\n",
        "        Opens an XDMF archive file, and extract a data mesh object for every timestep.\n",
        "\n",
        "        xdmf_file_path: path to the .xdmf file.\n",
        "        Returns: list of data mesh objects.\n",
        "        \"\"\"\n",
        "\n",
        "        reader = meshio.xdmf.TimeSeriesReader(xdmf_file_path)\n",
        "        points, cells = reader.read_points_cells()\n",
        "        meshes = []\n",
        "\n",
        "        # Extracting the meshes from the archive\n",
        "        for i in [t,t+1]:\n",
        "            # Depending on meshio version, the function read_data may return 3 or 4 values.\n",
        "            try:\n",
        "                time, point_data, cell_data, _ = reader.read_data(i)\n",
        "            except ValueError:\n",
        "                time, point_data, cell_data = reader.read_data(i)\n",
        "            mesh = meshio.Mesh(points, cells, point_data=point_data, cell_data=cell_data)\n",
        "            meshes.append(mesh)\n",
        "        #print(f\"Loaded {len(meshes)} timesteps from {xdmf_file_path.split('/')[-1]}\\n\")\n",
        "        return meshes\n",
        "\n",
        "\n",
        "#folder_path = '/content/drive/MyDrive/IDSC/4Students_AnXplore03/'\n",
        "#folder_path = '../input/anevrisme/4Students_AnXplore03/'\n",
        "\n",
        "# dataset = Dataset(folder_path)\n",
        "# train_loader = DataLoader(\n",
        "#     dataset=dataset,\n",
        "#     batch_size=1,\n",
        "#     shuffle=True,\n",
        "#     num_workers=0,\n",
        "# )\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_scatter import scatter_add\n",
        "\n",
        "def build_mlp(\n",
        "    in_size: int,\n",
        "    hidden_size: int,\n",
        "    out_size: int,\n",
        "    nb_of_layers: int = 4,\n",
        "    lay_norm: bool = True,\n",
        ") -> nn.Module:\n",
        "    \"\"\"\n",
        "    Builds a Multilayer Perceptron (MLP) using PyTorch.\n",
        "\n",
        "    Parameters:\n",
        "        - in_size (int): The size of the input layer.\n",
        "        - hidden_size (int): The size of the hidden layers.\n",
        "        - out_size (int): The size of the output layer.\n",
        "        - nb_of_layers (int, optional): The number of layers in the MLP, including the input and output layers. Defaults to 4.\n",
        "\n",
        "    Returns:\n",
        "        - nn.Module: The constructed MLP model.\n",
        "    \"\"\"\n",
        "    # Initialize the model with the first layer.\n",
        "    layers = []\n",
        "    layers.append(nn.Linear(in_size,hidden_size))\n",
        "    layers.append(nn.ReLU())\n",
        "\n",
        "    if lay_norm:\n",
        "      layers.append(nn.LayerNorm(hidden_size))\n",
        "\n",
        "    for _ in range(nb_of_layers - 2):\n",
        "      layers.append(nn.Linear(hidden_size,hidden_size))\n",
        "      layers.append(nn.ReLU())\n",
        "\n",
        "      if lay_norm:\n",
        "        layers.append(nn.LayerNorm(hidden_size))\n",
        "\n",
        "    # Add the output layer\n",
        "    layers.append(nn.Linear(hidden_size,out_size))\n",
        "    # Construct the model using the specified layers.\n",
        "    module = nn.Sequential(*layers)\n",
        "\n",
        "    return module\n",
        "\n",
        "class EdgeBlock(nn.Module):\n",
        "    \"\"\"A block that updates the attributes of the edges in a graph based on the features of the\n",
        "    sending and receiving nodes, as well as the original edge attributes.\n",
        "\n",
        "    Attributes:\n",
        "        model_fn (callable): A function to update edge attributes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_fn=None):\n",
        "\n",
        "        super(EdgeBlock, self).__init__()\n",
        "        self._model_fn = model_fn\n",
        "\n",
        "    def forward(self, graph):\n",
        "        \"\"\"Forward pass of the EdgeBlock.\n",
        "\n",
        "        Args:\n",
        "            graph (Data): A graph containing node attributes, edge indices, and edge attributes.\n",
        "\n",
        "        Returns:\n",
        "            Data: An updated graph with new edge attributes.\n",
        "        \"\"\"\n",
        "        edge_index = graph.edge_index.long() # Ensure edge_index is of type long\n",
        "        edge_inputs = torch.concat(\n",
        "            [\n",
        "                graph.edge_attr,\n",
        "                graph.x[edge_index[0]],\n",
        "                graph.x[edge_index[1]]\n",
        "            ], dim=1\n",
        "        )\n",
        "\n",
        "        edge_attr_ = self._model_fn(edge_inputs)\n",
        "        return Data(\n",
        "                x=graph.x, edge_attr=edge_attr_, edge_index=graph.edge_index, pos=graph.pos\n",
        "            )\n",
        "\n",
        "\n",
        "class NodeBlock(nn.Module):\n",
        "    \"\"\"A block that updates the attributes of the nodes in a graph based on the aggregated features\n",
        "    of the incoming edges and the original node attributes.\n",
        "\n",
        "    Attributes:\n",
        "        model_fn (callable): A function to update node attributes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_fn=None):\n",
        "\n",
        "        super(NodeBlock, self).__init__()\n",
        "\n",
        "        self._model_fn = model_fn\n",
        "\n",
        "    def forward(self, graph):\n",
        "        \"\"\"Forward pass of the NodeBlock.\n",
        "\n",
        "        Args:\n",
        "            graph (Data): A graph containing node attributes, edge indices, and edge attributes.\n",
        "\n",
        "        Returns:\n",
        "            Data: An updated graph with new node attributes.\n",
        "        \"\"\"\n",
        "        edge_index = graph.edge_index.long()  # Ensure edge_index is of type long\n",
        "        edge_attr = graph.edge_attr\n",
        "        receivers_indx = edge_index[1]\n",
        "        agrr_edge_features = scatter_add(\n",
        "            edge_attr, receivers_indx, dim=0, dim_size=graph.num_nodes\n",
        "        )\n",
        "\n",
        "        node_inputs = torch.cat(\n",
        "            [graph.x, agrr_edge_features], dim=-1\n",
        "        )\n",
        "\n",
        "        x_ = self._model_fn(node_inputs)\n",
        "        return Data(\n",
        "                x=x_, edge_attr=graph.edge_attr, edge_index=graph.edge_index, pos=graph.pos\n",
        "            )\n",
        "\n",
        "class GraphNetBlock(nn.Module):\n",
        "    \"\"\"A block that sequentially applies an EdgeBlock and a NodeBlock to update the attributes of\n",
        "    both edges and nodes in a graph.\n",
        "\n",
        "    Attributes:\n",
        "        edge_block (EdgeBlock): The block to update edge attributes.\n",
        "        node_block (NodeBlock): The block to update node attributes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size=128,\n",
        "        use_batch=False,\n",
        "        use_gated_mlp=False,\n",
        "        use_gated_lstm=False,\n",
        "        use_gated_mha=False,\n",
        "    ):\n",
        "\n",
        "        super(GraphNetBlock, self).__init__()\n",
        "\n",
        "        edge_input_dim = 3*hidden_size #\n",
        "        node_input_dim = 2*hidden_size #\n",
        "\n",
        "        self.edge_block = EdgeBlock(model_fn=build_mlp(\n",
        "            in_size=edge_input_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            out_size=hidden_size,\n",
        "        )) #\n",
        "        self.node_block = NodeBlock(\n",
        "            model_fn=build_mlp(\n",
        "                in_size=node_input_dim,\n",
        "                hidden_size=hidden_size,\n",
        "                out_size=hidden_size,\n",
        "            )\n",
        "        ) #\n",
        "\n",
        "    def _apply_sub_block(self, graph):\n",
        "        graph = self.edge_block(graph)\n",
        "        return self.node_block(graph)\n",
        "\n",
        "    def forward(self, graph):\n",
        "        graph_last = graph.clone()\n",
        "        graph = self._apply_sub_block(graph)\n",
        "        edge_attr = graph_last.edge_attr + graph.edge_attr\n",
        "        x = graph_last.x + graph.x\n",
        "        return Data(\n",
        "                x=x, edge_attr=edge_attr, edge_index=graph.edge_index, pos=graph.pos\n",
        "            )\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "import shutil\n",
        "from itertools import product\n",
        "import meshio\n",
        "from typing import List\n",
        "from torch.utils.data import Dataset as BaseDataset\n",
        "from torch_geometric.data import Data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch_geometric.loader import DataLoader\n",
        "#from MessagePassing import GraphNetBlock\n",
        "\n",
        "def build_mlp(\n",
        "    in_size: int,\n",
        "    hidden_size: int,\n",
        "    out_size: int,\n",
        "    nb_of_layers: int = 4,\n",
        "    lay_norm: bool = True,\n",
        ") -> nn.Module:\n",
        "    \"\"\"\n",
        "    Builds a Multilayer Perceptron (MLP) using PyTorch.\n",
        "\n",
        "    Parameters:\n",
        "        - in_size (int): The size of the input layer.\n",
        "        - hidden_size (int): The size of the hidden layers.\n",
        "        - out_size (int): The size of the output layer.\n",
        "        - nb_of_layers (int, optional): The number of layers in the MLP, including the input and output layers. Defaults to 4.\n",
        "\n",
        "    Returns:\n",
        "        - nn.Module: The constructed MLP model.\n",
        "    \"\"\"\n",
        "    # Initialize the model with the first layer.\n",
        "    layers = []\n",
        "    layers.append(nn.Linear(in_size,hidden_size))\n",
        "    layers.append(nn.ReLU())\n",
        "\n",
        "    if lay_norm:\n",
        "      layers.append(nn.LayerNorm(hidden_size))\n",
        "\n",
        "    for _ in range(nb_of_layers - 2):\n",
        "      layers.append(nn.Linear(hidden_size,hidden_size))\n",
        "      layers.append(nn.ReLU())\n",
        "\n",
        "      if lay_norm:\n",
        "        layers.append(nn.LayerNorm(hidden_size))\n",
        "\n",
        "    # Add the output layer\n",
        "    layers.append(nn.Linear(hidden_size,out_size))\n",
        "    # Construct the model using the specified layers.\n",
        "    module = nn.Sequential(*layers)\n",
        "\n",
        "    return module\n",
        "\n",
        "def convert_to_float(data):\n",
        "    \"\"\"Convertit toutes les données d'un objet Data en float.\n",
        "\n",
        "    Args:\n",
        "        data (Data): L'objet Data à convertir.\n",
        "\n",
        "    Returns:\n",
        "        Data: L'objet Data avec toutes les données converties en float.\n",
        "    \"\"\"\n",
        "\n",
        "    for key, value in data:\n",
        "        if isinstance(value, torch.Tensor) and value.dtype == torch.float64:\n",
        "            data[key] = value.to(torch.float32)\n",
        "\n",
        "    return data\n",
        "\n",
        "##################################\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"Encoder class for encoding graph structures into latent representations.\n",
        "\n",
        "    This encoder takes a graph as input and produces latent representations for both nodes and edges.\n",
        "    It utilizes MLPs (Multi-Layer Perceptrons) to encode the node and edge attributes into a latent space.\n",
        "\n",
        "    Attributes:\n",
        "        - edge_encoder (nn.Module): MLP for encoding edge attributes.\n",
        "        - nodes_encoder (nn.Module): MLP for encoding node attributes.\n",
        "\n",
        "    Args:\n",
        "        - edge_input_size (int): Size of the input edge features. Defaults to 128.\n",
        "        - node_input_size (int): Size of the input node features. Defaults to 128.\n",
        "        - hidden_size (int): Size of the hidden layers in the MLPs. Defaults to 128.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, edge_input_size=3, node_input_size=6, hidden_size=128, nb_of_layers=4\n",
        "    ):\n",
        "\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.node_encoder = build_mlp(\n",
        "            in_size=node_input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            out_size=hidden_size,\n",
        "            nb_of_layers=nb_of_layers\n",
        "        )\n",
        "        self.edge_encoder = build_mlp(\n",
        "            in_size=edge_input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            out_size=hidden_size,\n",
        "            nb_of_layers=nb_of_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, graph: Data) -> Data:\n",
        "        \"\"\"\n",
        "        Forward pass of the encoder.\n",
        "\n",
        "        Args:\n",
        "            - graph (Data): A graph object from torch_geometric containing node and edge attributes.\n",
        "\n",
        "        Returns:\n",
        "            - Data: A graph object with encoded node and edge attributes.\n",
        "        \"\"\"\n",
        "        graph = convert_to_float(graph)\n",
        "        node_latents = self.node_encoder(graph.x)\n",
        "        edge_latents = self.edge_encoder(graph.edge_attr)\n",
        "\n",
        "        return Data(\n",
        "            x=node_latents,\n",
        "            edge_index=graph.edge_index,\n",
        "            edge_attr=edge_latents,\n",
        "            y=graph.y,\n",
        "            pos=graph.pos,\n",
        "        )\n",
        "\n",
        "#########################\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"Decoder class for decoding latent representations back into graph structures.\n",
        "\n",
        "    This decoder takes the latent representations of nodes (and potentially edges) and decodes them back into\n",
        "    graph space, aiming to reconstruct the original graph or predict certain properties of the graph.\n",
        "\n",
        "    Attributes:\n",
        "        decode_module (nn.Module): An MLP module used for decoding the latent representations.\n",
        "\n",
        "    Args:\n",
        "        hidden_size (int): The size of the hidden layers in the MLP. This is also the size of the latent representation.\n",
        "        output_size (int): The size of the output layer, which should match the dimensionality of the target graph space.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, hidden_size: int = 128, output_size_node: int = 6,output_size_edge: int=3,  nb_of_layers: int = 4\n",
        "    ):\n",
        "\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.decode_module = build_mlp(in_size=hidden_size, hidden_size=hidden_size, out_size=output_size_node, nb_of_layers=nb_of_layers)\n",
        "        self.decode_edge = build_mlp(in_size=hidden_size, hidden_size=hidden_size, out_size=output_size_edge, nb_of_layers=nb_of_layers)\n",
        "\n",
        "    def forward(self, graph: Data) -> Data:\n",
        "        \"\"\"Forward pass of the decoder.\n",
        "\n",
        "        Args:\n",
        "            graph (Data): A graph object from torch_geometric containing the latent representations of nodes.\n",
        "\n",
        "        Returns:\n",
        "            Data: A graph object where `x` has been decoded from the latent space back into the original graph space.\n",
        "                  The structure of the graph (edges) remains unchanged.\n",
        "        \"\"\"\n",
        "        graph_x = self.decode_module(graph.x)\n",
        "        graph_edge = self.decode_edge(graph.edge_attr)\n",
        "\n",
        "        return Data(\n",
        "            x=graph_x,\n",
        "            edge_index=graph.edge_index,\n",
        "            edge_attr=graph_edge,\n",
        "            y=graph.y,\n",
        "            pos=graph.pos,\n",
        "        )\n",
        "  ####################################\"\n",
        "\n",
        "\n",
        "class EncodeProcessDecode(nn.Module):\n",
        "    \"\"\"An Encode-Process-Decode model for graph neural networks.\n",
        "\n",
        "    This model architecture is designed for processing graph-structured data. It consists of three main components:\n",
        "    an encoder, a processor, and a decoder. The encoder maps input graph features to a latent space, the processor\n",
        "    performs message passing and updates node representations, and the decoder generates the final output from the\n",
        "    processed graph.\n",
        "\n",
        "    Attributes:\n",
        "        encoder (Encoderge): The encoder component that transforms input graph features to a latent representation.\n",
        "        decoder (Decoder): The decoder component that generates output from the processed graph.\n",
        "        processer_list (nn.ModuleList): A list of GraphNetBlock modules for message passing and node updates.\n",
        "\n",
        "    Parameters:\n",
        "        message_passing_num (int): The number of message passing (GraphNetBlock) layers.\n",
        "        node_input_size (int): The size of the input node features.\n",
        "        edge_input_size (int): The size of the input edge features.\n",
        "        output_size (int): The size of the output features.\n",
        "        hidden_size (int, optional): The size of the hidden layers. Defaults to 128.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        message_passing_num,\n",
        "        node_input_size,\n",
        "        edge_input_size,\n",
        "        node_output_size,\n",
        "        edge_output_size,\n",
        "        hidden_size=128,\n",
        "    ):\n",
        "\n",
        "        super(EncodeProcessDecode, self).__init__()\n",
        "        self.encoder = Encoder(\n",
        "                               edge_input_size=edge_input_size,\n",
        "                               node_input_size=node_input_size,\n",
        "                               hidden_size=hidden_size\n",
        "                               )\n",
        "\n",
        "        self.decoder = Decoder(hidden_size=hidden_size, output_size_node=node_output_size, output_size_edge=edge_output_size)\n",
        "\n",
        "        self.processer_list = nn.ModuleList(\n",
        "                [\n",
        "                    GraphNetBlock(hidden_size=hidden_size)\n",
        "                    for _ in range(message_passing_num)\n",
        "                ]\n",
        "        )\n",
        "\n",
        "    def forward(self, graph):\n",
        "        \"\"\"Forward pass of the Encode-Process-Decode model.\n",
        "\n",
        "        Args:\n",
        "            graph: The input graph data. The exact type and format depend on the implementation of the Encoder and\n",
        "                   GraphNetBlock modules.\n",
        "\n",
        "        Returns:\n",
        "            The output of the model after encoding, processing, and decoding the input graph.\n",
        "        \"\"\"\n",
        "        graph = self.encoder(graph)\n",
        "\n",
        "        for processer in self.processer_list:\n",
        "            graph = processer(graph)\n",
        "\n",
        "        graph = self.decoder(graph)\n",
        "\n",
        "        return graph\n",
        "\n",
        "from tqdm import tqdm as tqdm\n",
        "import sys\n",
        "\n",
        "class Epoch:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        loss,\n",
        "        stage_name,\n",
        "        parameters,\n",
        "        device=\"cpu\",\n",
        "        verbose=True,\n",
        "        starting_step=0,\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.loss = loss\n",
        "        self.verbose = verbose\n",
        "        self.device = device\n",
        "        self.parameters = parameters\n",
        "        self.step = 0\n",
        "        self._to_device()\n",
        "        self.stage_name = stage_name\n",
        "        self.starting_step = starting_step\n",
        "        print(\"Epoch\", self.device)\n",
        "\n",
        "    def _to_device(self):\n",
        "        self.model.to(self.device)\n",
        "        self.loss.to(self.device)\n",
        "\n",
        "    def _format_logs(self, logs):\n",
        "        str_logs = [\"{} - {:.4}\".format(k, v) for k, v in logs.items()]\n",
        "        s = \", \".join(str_logs)\n",
        "        return s\n",
        "\n",
        "    def batch_update(self, x, y):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def on_epoch_start(self):\n",
        "        pass\n",
        "\n",
        "    def run(self, dataloader, writer=None, model_save_dir=\"checkpoint/simulator.pth\"):\n",
        "        self.on_epoch_start()\n",
        "        logs = {}\n",
        "        loss_meter = AverageValueMeter()\n",
        "\n",
        "        with tqdm(dataloader, desc=self.stage_name, file=sys.stdout, disable=not (self.verbose)) as iterator:\n",
        "            for graph_data in iterator:\n",
        "                batch_loss = self.batch_update([graph_data], writer)\n",
        "                batch_loss_value = batch_loss.detach().cpu().item()  # Convert to CPU float\n",
        "                loss_meter.add(batch_loss_value)\n",
        "                del graph_data, batch_loss_value  # Explicitly delete variables\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()  # Force garbage collection\n",
        "\n",
        "        return loss_meter.mean\n",
        "\n",
        "import time\n",
        "\n",
        "class TrainEpoch(Epoch):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        loss,\n",
        "        parameters,\n",
        "        optimizer,\n",
        "        device=\"cpu\",\n",
        "        verbose=True,\n",
        "        starting_step=0,\n",
        "        use_sub_graph=False,\n",
        "        accumulation_steps=4  # Add accumulation steps for gradient accumulation\n",
        "    ):\n",
        "        super().__init__(\n",
        "            model=model,\n",
        "            loss=loss,\n",
        "            stage_name=\"train\",\n",
        "            parameters=parameters,\n",
        "            device=device,\n",
        "            verbose=verbose,\n",
        "            starting_step=starting_step,\n",
        "        )\n",
        "        self.optimizer = optimizer\n",
        "        self.use_sub_graph = use_sub_graph\n",
        "        self.accumulation_steps = accumulation_steps\n",
        "\n",
        "    def on_epoch_start(self):\n",
        "        self.model.train()\n",
        "\n",
        "\n",
        "    def batch_update(self, batch_graph, writer):\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = 0\n",
        "        #TODO: check that batch_graph is either a list of graphs of a list of one list of graphs\n",
        "        for i, graph in enumerate(batch_graph):\n",
        "            node_type = graph['x'][:, self.model.node_type_index]\n",
        "            network_output, target_delta_normalized = self.model(graph)\n",
        "\n",
        "\n",
        "            loss += self.loss(\n",
        "                target_delta_normalized,\n",
        "                network_output,\n",
        "                node_type,\n",
        "            )\n",
        "\n",
        "            if (i + 1) % self.accumulation_steps == 0:\n",
        "                loss /= self.accumulation_steps\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                max_norm = 10.0\n",
        "                nn.utils.clip_grad_norm_(self.model.parameters(), max_norm)\n",
        "\n",
        "                self.optimizer.step()\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                loss = 0\n",
        "\n",
        "\n",
        "        if loss > 0:\n",
        "            loss /= self.accumulation_steps\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            max_norm = 10.0\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), max_norm)\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "        del batch_graph, network_output, target_delta_normalized, node_type  # Explicitly delete variables\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()  # Force garbage collection\n",
        "\n",
        "        return loss\n",
        "\n",
        "from loguru import logger\n",
        "import os\n",
        "import enum\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.loss import _Loss\n",
        "from torch_geometric.data import Data\n",
        "import meshio\n",
        "import shutil\n",
        "import os.path as osp\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class Meter(object):\n",
        "    \"\"\"Meters provide a way to keep track of important statistics in an online manner.\n",
        "    This class is abstract, but provides a standard interface for all meters to follow.\n",
        "    \"\"\"\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the meter to default settings.\"\"\"\n",
        "\n",
        "    def add(self, value):\n",
        "        \"\"\"Log a new value to the meter\n",
        "        Args:\n",
        "            value: Next result to include.\n",
        "        \"\"\"\n",
        "\n",
        "    def value(self):\n",
        "        \"\"\"Get the value of the meter in the current state.\"\"\"\n",
        "\n",
        "\n",
        "class AverageValueMeter(Meter):\n",
        "    def __init__(self):\n",
        "        super(AverageValueMeter, self).__init__()\n",
        "        self.reset()\n",
        "        self.val = 0\n",
        "\n",
        "    def add(self, value, n=1):\n",
        "        self.val = value\n",
        "        self.sum += value\n",
        "        self.var += value * value\n",
        "        self.n += n\n",
        "\n",
        "        if self.n == 0:\n",
        "            self.mean, self.std = np.nan, np.nan\n",
        "        elif self.n == 1:\n",
        "            self.mean = 0.0 + self.sum  # This is to force a copy in torch/numpy\n",
        "            self.std = np.inf\n",
        "            self.mean_old = self.mean\n",
        "            self.m_s = 0.0\n",
        "        else:\n",
        "            self.mean = self.mean_old + (value - n * self.mean_old) / float(self.n)\n",
        "            self.m_s += (value - self.mean_old) * (value - self.mean)\n",
        "            self.mean_old = self.mean\n",
        "            self.std = np.sqrt(self.m_s / (self.n - 1.0))\n",
        "\n",
        "    def value(self):\n",
        "        return self.mean, self.std\n",
        "\n",
        "    def reset(self):\n",
        "        self.n = 0\n",
        "        self.sum = 0.0\n",
        "        self.var = 0.0\n",
        "        self.val = 0.0\n",
        "        self.mean = np.nan\n",
        "        self.mean_old = 0.0\n",
        "        self.m_s = 0.0\n",
        "        self.std = np.nan\n",
        "\n",
        "class L2Loss(_Loss):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    @property\n",
        "    def __name__(self):\n",
        "        return \"MSE\"\n",
        "\n",
        "    def forward(\n",
        "        self, target_speed, network_output, node_type\n",
        "    ):\n",
        "        \"Computes L2 loss on velocity, with respect to the noise\"\n",
        "        mask = (node_type == 1)\n",
        "        target_speed_tensor = target_speed.to(torch.float32)\n",
        "        network_output_tensor = network_output.x.to(torch.float32)\n",
        "\n",
        "        errors = (target_speed_tensor[mask] - network_output_tensor[mask]) ** 2\n",
        "        return torch.mean(errors)\n",
        "\n",
        "class Normalizer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        size,\n",
        "        max_accumulations=10**5,\n",
        "        std_epsilon=1e-8,\n",
        "        name=\"Normalizer\",\n",
        "        device=\"cuda\",\n",
        "    ):\n",
        "        \"\"\"Initializes the Normalizer module.\n",
        "\n",
        "        Args:\n",
        "            size (int): Size of the input data.\n",
        "            max_accumulations (int): Maximum number of accumulations allowed.\n",
        "            std_epsilon (float): Epsilon value for standard deviation calculation.\n",
        "            name (str): Name of the Normalizer.\n",
        "            device (str): Device to run the Normalizer on.\n",
        "        \"\"\"\n",
        "        #print(\"Normalizer\", device)\n",
        "        super(Normalizer, self).__init__()\n",
        "        self.name = name\n",
        "        self._max_accumulations = max_accumulations\n",
        "        self._std_epsilon = torch.tensor(\n",
        "            std_epsilon, dtype=torch.float32, requires_grad=False, device=device\n",
        "        )\n",
        "        self._acc_count = torch.tensor(\n",
        "            0, dtype=torch.float32, requires_grad=False, device=device\n",
        "        )\n",
        "        self._num_accumulations = torch.tensor(\n",
        "            0, dtype=torch.float32, requires_grad=False, device=device\n",
        "        )\n",
        "        self._acc_sum = torch.zeros(\n",
        "            (1, size), dtype=torch.float32, requires_grad=False, device=device\n",
        "        )\n",
        "        self._acc_sum_squared = torch.zeros(\n",
        "            (1, size), dtype=torch.float32, requires_grad=False, device=device\n",
        "        )\n",
        "        self._std_zeros = torch.zeros(\n",
        "            (1, size), dtype=torch.float32, requires_grad=False, device=device\n",
        "        )\n",
        "\n",
        "    def forward(self, batched_data, accumulate=True):\n",
        "        \"\"\"Normalizes input data and accumulates statistics.\"\"\"\n",
        "        if accumulate:\n",
        "            # stop accumulating after a million updates, to prevent accuracy issues\n",
        "            if self._num_accumulations < self._max_accumulations:\n",
        "                self._accumulate(batched_data.detach())\n",
        "        return (batched_data - self._mean()) / self._std_with_epsilon()\n",
        "\n",
        "    def inverse(self, normalized_batch_data):\n",
        "        \"\"\"Inverse transformation of the normalizer.\"\"\"\n",
        "        return normalized_batch_data * self._std_with_epsilon() + self._mean()\n",
        "\n",
        "    def _accumulate(self, batched_data):\n",
        "        \"\"\"Function to perform the accumulation of the batch_data statistics.\"\"\"\n",
        "        count = batched_data.shape[0]\n",
        "        data_sum = torch.sum(batched_data, axis=0, keepdims=True)\n",
        "        squared_data_sum = torch.sum(batched_data**2, axis=0, keepdims=True)\n",
        "\n",
        "        self._acc_sum += data_sum\n",
        "        self._acc_sum_squared += squared_data_sum\n",
        "        self._acc_count += count\n",
        "        self._num_accumulations += 1\n",
        "\n",
        "    def _mean(self):\n",
        "        safe_count = torch.maximum(\n",
        "            self._acc_count,\n",
        "            torch.tensor(1.0, dtype=torch.float32, device=self._acc_count.device),\n",
        "        )\n",
        "        return self._acc_sum / safe_count\n",
        "\n",
        "    def _std_with_epsilon(self):\n",
        "        safe_count = torch.maximum(\n",
        "            self._acc_count,\n",
        "            torch.tensor(1.0, dtype=torch.float32, device=self._acc_count.device),\n",
        "        )\n",
        "        std = torch.sqrt(\n",
        "            torch.maximum(\n",
        "                self._std_zeros, self._acc_sum_squared / safe_count - self._mean() ** 2\n",
        "            )\n",
        "        )\n",
        "        return torch.maximum(std, self._std_epsilon)\n",
        "\n",
        "    def get_variable(self):\n",
        "\n",
        "        dict = {\n",
        "            \"_max_accumulations\": self._max_accumulations,\n",
        "            \"_std_epsilon\": self._std_epsilon,\n",
        "            \"_acc_count\": self._acc_count,\n",
        "            \"_num_accumulations\": self._num_accumulations,\n",
        "            \"_acc_sum\": self._acc_sum,\n",
        "            \"_acc_sum_squared\": self._acc_sum_squared,\n",
        "            \"name\": self.name,\n",
        "        }\n",
        "\n",
        "        return dict\n",
        "\n",
        "import time\n",
        "\n",
        "class Simulator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_input_size: int,\n",
        "        edge_input_size: int,\n",
        "        output_size: int,\n",
        "        feature_index_start: int,\n",
        "        feature_index_end: int,\n",
        "        output_index_start: int,\n",
        "        output_index_end: int,\n",
        "        node_type_index: int,\n",
        "        batch_size: int,\n",
        "        model,\n",
        "        device,\n",
        "        model_dir='/content/drive/MyDrive/Groupe2/simulator_checkpoints',\n",
        "        time_index: int = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the Simulator module.\n",
        "\n",
        "        Args:\n",
        "            node_input_size (int): Size of node input.\n",
        "            edge_input_size (int): Size of edge input.\n",
        "            output_size (int): Size of the output/prediction from the network.\n",
        "            feature_index_start (int): Start index of features.\n",
        "            feature_index_end (int): End index of features.\n",
        "            output_index_start (int): Start index of output.\n",
        "            output_index_end (int): End index of output.\n",
        "            node_type_index (int): Index of node type.\n",
        "            model: The model to be used.\n",
        "            device: The device to run the model on.\n",
        "            model_dir (str): Directory to save the model checkpoint.\n",
        "            time_index (int): Index of time feature.\n",
        "        \"\"\"\n",
        "        super(Simulator, self).__init__()\n",
        "\n",
        "        self.node_input_size = node_input_size\n",
        "        self.edge_input_size = edge_input_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.feature_index_start = feature_index_start\n",
        "        self.feature_index_end = feature_index_end\n",
        "        self.node_type_index = node_type_index\n",
        "\n",
        "        self.time_index = time_index\n",
        "\n",
        "        self.output_index_start = output_index_start\n",
        "        self.output_index_end = output_index_end\n",
        "\n",
        "        self.model_dir = model_dir\n",
        "        self.model = model.to(device)\n",
        "        #start_time = time.time()\n",
        "        self._output_normalizer = Normalizer(\n",
        "            size=output_size, name=\"output_normalizer\", device=device\n",
        "        )\n",
        "        self._node_normalizer = Normalizer(\n",
        "            size=node_input_size, name=\"node_normalizer\", device=device\n",
        "        )\n",
        "        self._edge_normalizer = Normalizer(\n",
        "            size=edge_input_size, name=\"edge_normalizer\", device=device\n",
        "        )\n",
        "        #print(\"Normalizer time: %f\" % (time.time() - start_time))\n",
        "\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def _get_pre_target(self, inputs: Data) -> torch.Tensor:\n",
        "        return inputs.x[:, self.output_index_start : self.output_index_end]\n",
        "\n",
        "    def _build_input_graph(self, inputs: Data, is_training: bool) -> Data:\n",
        "        node_type = inputs.x[:, self.node_type_index]\n",
        "        features = inputs.x[:, self.feature_index_start : self.feature_index_end]\n",
        "\n",
        "        target = inputs.y\n",
        "        pre_target = self._get_pre_target(inputs)\n",
        "\n",
        "        target_delta = target - pre_target\n",
        "        target_delta_normalized = self._output_normalizer(target_delta, is_training)\n",
        "\n",
        "        node_features = inputs.x\n",
        "        node_features_normalized = self._node_normalizer(node_features, is_training)\n",
        "        edge_features_normalized = self._edge_normalizer(\n",
        "                    inputs.edge_attr, is_training)\n",
        "\n",
        "        graph = Data(\n",
        "                x=node_features_normalized,\n",
        "                pos=inputs.pos,\n",
        "                edge_attr=edge_features_normalized,\n",
        "                edge_index=inputs.edge_index,\n",
        "            ).to(device=self.device, non_blocking=True)\n",
        "        # Free up memory\n",
        "        torch.cuda.empty_cache()\n",
        "        return graph, target_delta_normalized\n",
        "\n",
        "    def _build_outputs(\n",
        "        self, inputs: Data, network_output: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        pre_target = self._get_pre_target(inputs)\n",
        "        update = self._output_normalizer.inverse(network_output)\n",
        "        return pre_target + update\n",
        "\n",
        "    def forward(self, inputs: Data):\n",
        "        #print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
        "        #print('device',torch.cuda.current_device())\n",
        "        if self.training:\n",
        "            #start_time = time.time()\n",
        "            graph, target_delta_normalized = self._build_input_graph(\n",
        "                inputs=inputs, is_training=True\n",
        "            )\n",
        "            #print(\"Graph creation\", time.time()-start_time)\n",
        "            #start_time = time.time()\n",
        "            network_output = self.model(graph)\n",
        "            #print(\"Network time\", time.time()-start_time)\n",
        "            #print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
        "            #print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
        "            #print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
        "            #print('device',torch.cuda.current_device())\n",
        "            return network_output, target_delta_normalized\n",
        "        else:\n",
        "            graph, target_delta_normalized = self._build_input_graph(\n",
        "                inputs=inputs, is_training=False\n",
        "            )\n",
        "            network_output = self.model(graph)\n",
        "            #print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
        "            #print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
        "            #print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
        "            return (\n",
        "                network_output,\n",
        "                target_delta_normalized,\n",
        "                self._build_outputs(inputs=inputs, network_output=network_output),\n",
        "            )\n",
        "\n",
        "    def freeze_all(self):\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def load_checkpoint(self, ckpdir=None):\n",
        "\n",
        "        if ckpdir is None:\n",
        "            ckpdir = self.model_dir\n",
        "        dicts = torch.load(ckpdir, map_location=torch.device(self.device))\n",
        "        self.load_state_dict(dicts[\"model\"])\n",
        "\n",
        "        keys = list(dicts.keys())\n",
        "        keys.remove(\"model\")\n",
        "\n",
        "        for k in keys:\n",
        "            v = dicts[k]\n",
        "            for para, value in v.items():\n",
        "                object = eval(\"self.\" + k)\n",
        "                setattr(object, para, value)\n",
        "\n",
        "        logger.success(\"Simulator model loaded checkpoint %s\" % ckpdir)\n",
        "\n",
        "    def save_checkpoint(self, savedir=None):\n",
        "        if savedir is None:\n",
        "            savedir = self.model_dir\n",
        "\n",
        "        os.makedirs(os.path.dirname(self.model_dir), exist_ok=True)\n",
        "\n",
        "        model = self.state_dict()\n",
        "        _output_normalizer = self._output_normalizer.get_variable()\n",
        "        _node_normalizer = self._node_normalizer.get_variable()\n",
        "        _edge_normalizer = self._edge_normalizer.get_variable()\n",
        "\n",
        "        to_save = {\n",
        "            \"model\": model,\n",
        "            \"_output_normalizer\": _output_normalizer,\n",
        "            \"_node_normalizer\": _node_normalizer,\n",
        "            \"_edge_normalizer\": _edge_normalizer,\n",
        "        }\n",
        "\n",
        "        torch.save(to_save, savedir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QA1IpUhtvsm",
        "outputId": "bfaaba5c-25ec-4a80-b47b-a6a2a0fa851a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch cuda\n",
            "\n",
            "Epoch: 0\n",
            "=== Training ===\n",
            "train: 100%|██████████| 8137/8137 [2:24:00<00:00,  1.06s/it]\n",
            "Epoch 0 completed with train_loss: 0.31672815726658987\n",
            "Model saved to /content/drive/MyDrive/simulator_checkpoints/simulator_epoch_0.pth\n",
            "\n",
            "Epoch: 1\n",
            "=== Training ===\n",
            "train:  54%|█████▍    | 4408/8137 [1:16:43<1:07:45,  1.09s/it]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch_geometric.loader import DataLoader\n",
        "#from DataLoader import Dataset\n",
        "#from EncoderDecoder import EncodeProcessDecode\n",
        "#from Utils import L2Loss, Simulator\n",
        "#from Epoch import TrainEpoch\n",
        "\n",
        "writer = SummaryWriter(\"tensorboard\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#print(device)\n",
        "folder_path = '/content/drive/MyDrive/IDSC/4Students_AnXplore03/'\n",
        "#folder_path =\"/Users/ludoviclepic/Downloads/4Students_AnXplore03/\"\n",
        "# folder_path = '../input/anevrisme/4Students_AnXplore03/'\n",
        "dataset = Dataset(folder_path)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=dataset,\n",
        "    batch_size=5,  # Use a smaller batch size to reduce memory usage\n",
        "    shuffle=True,\n",
        "    num_workers=0,  # Reduce the number of workers to avoid semaphore issues\n",
        "    pin_memory=False,  # Pin memory to speed up data transfer to GPU\n",
        "    persistent_workers=False  # Disable persistent workers to avoid semaphore issues\n",
        ")\n",
        "\n",
        "model = EncodeProcessDecode(\n",
        "    node_input_size=6,\n",
        "    edge_input_size=3,\n",
        "    message_passing_num=5,\n",
        "    hidden_size=32,\n",
        "    node_output_size=6,\n",
        "    edge_output_size=3,\n",
        ") #\n",
        "loss = L2Loss() #\n",
        "simulator = Simulator(\n",
        "    node_input_size=6,\n",
        "    edge_input_size=3,\n",
        "    output_size=6,\n",
        "    feature_index_start=0,\n",
        "    feature_index_end=4,\n",
        "    output_index_start=0,\n",
        "    output_index_end=6,\n",
        "    node_type_index=5,\n",
        "    batch_size=5,\n",
        "    model=model,\n",
        "    device=device,\n",
        "    model_dir=\"Groupe2/checkpoint/simulator.pth\",\n",
        "    time_index=4\n",
        ") #\n",
        "optimizer = torch.optim.Adam(simulator.parameters(), lr=0.0001)\n",
        "\n",
        "train_epoch = TrainEpoch(\n",
        "    model=simulator,\n",
        "    loss=loss,\n",
        "    optimizer=optimizer,\n",
        "    parameters={},\n",
        "    device=device,\n",
        "    verbose=True,\n",
        "    starting_step=0,\n",
        "    use_sub_graph=False,\n",
        "    accumulation_steps=4  # Set accumulation steps for gradient accumulation\n",
        ")\n",
        "\n",
        "import os\n",
        "\n",
        "# Ensure the Drive folder exists\n",
        "drive_checkpoint_folder = '/content/drive/MyDrive/Groupe2/simulator_checkpoints'\n",
        "os.makedirs(drive_checkpoint_folder, exist_ok=True)\n",
        "\n",
        "for i in range(0, 15):\n",
        "    print(\"\\nEpoch: {}\".format(i))\n",
        "    print(\"=== Training ===\")\n",
        "    train_loss = train_epoch.run(train_loader, writer, \"model.pth\")\n",
        "    print(f\"Epoch {i} completed with train_loss: {train_loss}\")\n",
        "\n",
        "    # Save the model directly to Google Drive\n",
        "    model_path = f\"{drive_checkpoint_folder}/simulator_epoch_{i}.pth\"\n",
        "    simulator.save_checkpoint()\n",
        "    torch.save(simulator.state_dict(), model_path)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "\n",
        "    writer.add_scalar(\"Loss/train/mean_value_per_epoch\", train_loss, i)\n",
        "    writer.flush()\n",
        "    writer.file_writer.flush()  # Clear the writer's logs\n",
        "\n",
        "writer.close()\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()  # Force garbage collection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bZhAyfB9faQk"
      },
      "outputs": [],
      "source": [
        "# !gdown 1wBh5wzOYgZ521GqwQyzV5oQv_PzwpiHs\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !mkdir /content/drive/MyDrive/IDSC\n",
        "# !unzip /content/IDSC2025_AnXplore_cropped_test_case.zip -d /content/drive/MyDrive/IDSC/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcHy8VC3hJR2"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def pred(nb_timestep, graph, graph0, model, device):\n",
        "    graph0 = graph0.to(device)\n",
        "    graph = graph.to(device)\n",
        "    model.to(device)\n",
        "    res = [graph0.cpu(), graph.cpu()]  # Store results on CPU to save GPU memory\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for i in range(nb_timestep):\n",
        "            start_time = time.time()\n",
        "            print(\"step:\", i, \" starting\")\n",
        "            output = model(graph)\n",
        "            graph = output.detach()  # Detach to prevent retaining computation graph\n",
        "            res.append(output.cpu())  # Move result to CPU and store\n",
        "            print(time.time()-start_time)\n",
        "            if device.type == \"cuda\":\n",
        "                torch.cuda.empty_cache()  # Clear GPU memory\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def predictions(folder_path, model_path, batch_size, num_workers, num_timestep_final, num_timestep_initial,\n",
        "                message_passing_num, hidden_size, device):\n",
        "    \"\"\"Load the model and generate predictions for given inputs.\"\"\"\n",
        "    dataset = Dataset(folder_path)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,  # Pin memory for better GPU performance\n",
        "        persistent_workers=False\n",
        "    )\n",
        "\n",
        "    model = EncodeProcessDecode(\n",
        "        node_input_size=6,\n",
        "        edge_input_size=3,\n",
        "        message_passing_num=message_passing_num,\n",
        "        hidden_size=hidden_size,\n",
        "        node_output_size=6,\n",
        "        edge_output_size=3\n",
        "    )\n",
        "\n",
        "    state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "\n",
        "    new_state_dict = {key.replace('model.', ''): value for key, value in state_dict.items()}\n",
        "    model.load_state_dict(new_state_dict)\n",
        "    model.eval()\n",
        "\n",
        "    return pred(num_timestep_final - num_timestep_initial,\n",
        "                train_loader.dataset[0],\n",
        "                train_loader.dataset[num_timestep_initial],\n",
        "                model,\n",
        "                device)\n",
        "\n",
        "\n",
        "# Test the prediction function\n",
        "directory_path = '/content/drive/MyDrive/IDSC/4Students_test_case_cropped/'\n",
        "model_path = '/content/drive/MyDrive/IDSC/simulator_epoch_0-2.pth'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the test dataset\n",
        "test_dataset = Dataset(directory_path)\n",
        "test_train_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=5,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,  # Optimize memory usage\n",
        "    persistent_workers=False\n",
        ")\n",
        "\n",
        "# Load the model\n",
        "model = EncodeProcessDecode(\n",
        "    node_input_size=6,\n",
        "    edge_input_size=3,\n",
        "    message_passing_num=5,\n",
        "    hidden_size=32,\n",
        "    node_output_size=6,\n",
        "    edge_output_size=3\n",
        ")\n",
        "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "new_state_dict = {key.replace('model.', ''): value for key, value in state_dict.items()}\n",
        "model.load_state_dict(new_state_dict)\n",
        "model.eval()\n",
        "\n",
        "# Test the `pred` function\n",
        "prediction = pred(78, test_train_loader.dataset[0], test_train_loader.dataset[2], model, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PDeWxeEUhaRu"
      },
      "outputs": [],
      "source": [
        "def xdmf_to_meshes(xdmf_file_path: str) -> List[meshio.Mesh]:\n",
        "    \"\"\"\n",
        "    Opens an XDMF archive file, and extract a data mesh object for every timestep.\n",
        "\n",
        "    xdmf_file_path: path to the .xdmf file.\n",
        "    Returns: list of data mesh objects.\n",
        "    \"\"\"\n",
        "\n",
        "    reader = meshio.xdmf.TimeSeriesReader(xdmf_file_path)\n",
        "    points, cells = reader.read_points_cells()\n",
        "    meshes = []\n",
        "\n",
        "    # Extracting the meshes from the archive\n",
        "    for i in range(reader.num_steps):\n",
        "        # Depending on meshio version, the function read_data may return 3 or 4 values.\n",
        "        try:\n",
        "            time, point_data, cell_data, _ = reader.read_data(i)\n",
        "        except ValueError:\n",
        "            time, point_data, cell_data = reader.read_data(i)\n",
        "        mesh = meshio.Mesh(points, cells, point_data=point_data, cell_data=cell_data)\n",
        "        meshes.append(mesh)\n",
        "    print(f\"Loaded {len(meshes)} timesteps from {xdmf_file_path.split('/')[-1]}\\n\")\n",
        "    return meshes\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import os.path as osp\n",
        "\n",
        "def meshes_to_xdmf(filename: str, meshes: List[meshio.Mesh], timestep=1) -> None:\n",
        "    \"\"\"\n",
        "    Writes a time series of meshes (same points and cells) into XDMF/HDF5 archive format.\n",
        "    The function will write two files: 'filename.xdmf' and 'filename.h5'.\n",
        "\n",
        "    filename: Chosen name for the archive files.\n",
        "    meshes: List of meshes to compress, they need to share their cells and points.\n",
        "    timestep: Timestep between two frames.\n",
        "    \"\"\"\n",
        "    points = meshes[0].points\n",
        "    cells = meshes[0].cells\n",
        "\n",
        "    # Generate output filenames\n",
        "    filename = osp.splitext(filename)[0]\n",
        "    h5_filename = f\"{filename}.h5\"\n",
        "    xdmf_filename = f\"{filename}.xdmf\"\n",
        "\n",
        "    # Use a temporary file for HDF5 to avoid conflicts\n",
        "    temp_h5_filename = tempfile.NamedTemporaryFile(delete=False).name\n",
        "\n",
        "    try:\n",
        "        # Open TimeSeriesWriter for XDMF\n",
        "        with meshio.xdmf.TimeSeriesWriter(xdmf_filename) as writer:\n",
        "            # Write mesh points and cells once\n",
        "            writer.write_points_cells(points, cells)\n",
        "\n",
        "            # Write time-varying data\n",
        "            for t, mesh in enumerate(meshes):\n",
        "                writer.write_data(\n",
        "                    t * timestep, point_data=mesh.point_data, cell_data=mesh.cell_data\n",
        "                )\n",
        "\n",
        "        # Ensure the HDF5 file is closed before moving it\n",
        "        if osp.exists(h5_filename):\n",
        "            os.remove(h5_filename)  # Remove existing file to avoid conflicts\n",
        "        shutil.move(temp_h5_filename, h5_filename)\n",
        "        print(f\"Time series written to {xdmf_filename} and {h5_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        # Clean up temporary files if an error occurs\n",
        "        if osp.exists(temp_h5_filename):\n",
        "            os.remove(temp_h5_filename)\n",
        "\n",
        "    finally:\n",
        "        # Ensure temporary files are cleaned up\n",
        "        if osp.exists(temp_h5_filename):\n",
        "            os.remove(temp_h5_filename)\n",
        "\n",
        "def graphs_to_meshes(graphs: List, initial_mesh: meshio.Mesh) -> List[meshio.Mesh]:\n",
        "    \"\"\"\n",
        "    Converts a list of graph data objects to a list of meshio.Mesh objects.\n",
        "\n",
        "    graphs: List of graph data objects containing node features (x).\n",
        "    initial_mesh: The initial mesh object (from timestep 0 or 1) containing points and cells.\n",
        "\n",
        "    Returns: List of meshio.Mesh objects for each timestep.\n",
        "    \"\"\"\n",
        "    points = initial_mesh.points\n",
        "    cells = initial_mesh.cells\n",
        "    meshes = []\n",
        "\n",
        "    for i, graph in enumerate(graphs):\n",
        "        # Extract Vitesse and Pression from graph.x\n",
        "        vitesse = graph.x[:, :3].cpu().numpy()  # First three columns\n",
        "        pression = graph.x[:, 3].cpu().numpy()  # Fourth column\n",
        "\n",
        "        # Create point data\n",
        "        point_data = {\n",
        "            \"Vitesse\": vitesse,\n",
        "            \"Pression\": pression\n",
        "        }\n",
        "\n",
        "        # Create a new mesh with the same points and cells, and updated point_data\n",
        "        mesh = meshio.Mesh(points, cells, point_data=point_data)\n",
        "        meshes.append(mesh)\n",
        "\n",
        "    print(f\"Converted {len(meshes)} graphs to meshes.\")\n",
        "    return meshes\n",
        "\n",
        "# Example usage:\n",
        "if not os.path.exists(directory_path):\n",
        "    os.makedirs(directory_path)\n",
        "    print(f\"Created directory: {directory_path}\")\n",
        "# Load the initial meshes from timestep 0 or 1\n",
        "file_path = '/content/drive/MyDrive/IDSC/4Students_test_case_cropped/TEST_AllFields_Resultats_MESH_1.xdmf'\n",
        "\n",
        "initial_meshes = xdmf_to_meshes(file_path)\n",
        "initial_mesh = initial_meshes[0]  # Assuming timestep 0\n",
        "\n",
        "# Convert the list of graphs to meshes\n",
        "list_of_graphs = prediction  # Your list of graph data objects\n",
        "meshes = graphs_to_meshes(list_of_graphs, initial_mesh)\n",
        "\n",
        "# Save the meshes to XDMF and HDF5\n",
        "output_filename = \"/content/drive/MyDrive/IDSC/output\"\n",
        "meshes_to_xdmf(output_filename, meshes, timestep=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1Qbg2Z9YhuUf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQbCMcy9iDce"
      },
      "outputs": [],
      "source": [
        "meshes_to_xdmf(\"output_mesh\", prediction1, timestep=len(prediction1), save_to_drive=False, drive_path=\"/content/drive/MyDrive/Meshes/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXFCbKpGn3uc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
